name: CI

on:
  push:
    branches: [ main ]
  pull_request:
    branches: [ main ]

jobs:
  test:
    runs-on: ubuntu-latest
    name: Test with Gemini (Default)
    
    services:
      postgres:
        image: pgvector/pgvector:pg15
        env:
          POSTGRES_DB: factorydb
          POSTGRES_USER: factoryadmin
          POSTGRES_PASSWORD: localpass
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 5432:5432

    steps:
      - uses: actions/checkout@v4
      
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.12'
          
      - name: Cache Python dependencies
        uses: actions/cache@v4
        with:
          path: ~/.cache/pip
          key: ${{ runner.os }}-pip-${{ hashFiles('**/requirements*.txt') }}
          restore-keys: |
            ${{ runner.os }}-pip-
            
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          # Install common development dependencies
          pip install black ruff pytest pytest-cov
          # Install project dependencies if they exist
          if [ -f requirements.txt ]; then pip install -r requirements.txt; fi
          if [ -f agents/dev/starter-api/requirements.txt ]; then pip install -r agents/dev/starter-api/requirements.txt; fi
          if [ -f orchestrator/requirements.txt ]; then pip install -r orchestrator/requirements.txt; fi
          
      - name: Validate orchestrator dependencies
        run: |
          if [ -f orchestrator/requirements.in ]; then
            echo "Checking orchestrator dependency lock file..."
            cd orchestrator
            pip install pip-tools
            pip-compile requirements.in --resolver=backtracking -o requirements.txt.tmp
            if ! diff -q requirements.txt requirements.txt.tmp > /dev/null; then
              echo "ERROR: requirements.txt is out of sync with requirements.in"
              echo "Please run: cd orchestrator && pip-compile requirements.in --resolver=backtracking -o requirements.txt"
              exit 1
            fi
            rm requirements.txt.tmp
            echo "âœ“ Orchestrator dependencies are in sync"
          fi
          
      - name: Create pgvector extension
        run: |
          PGPASSWORD=localpass psql -h localhost -U factoryadmin -d factorydb -c "CREATE EXTENSION IF NOT EXISTS vector;"
          
      - name: Lint with ruff
        run: |
          # Stop the build if there are Python syntax errors or undefined names
          ruff check --select=E9,F63,F7,F82 --statistics .
          # Exit-zero treats all errors as warnings
          ruff check --exit-zero --statistics .
          
      - name: Format check with black
        run: |
          black --check --diff .
          
      - name: Run tests
        run: |
          # Check for test files in project directories only (exclude venv and third-party)
          TEST_FILES=$(find . -name "*test*.py" -o -name "test_*.py" 2>/dev/null | grep -v -E "(\.venv|venv|env|y/google-cloud-sdk|orchestrator/\.venv)" | head -1)
          if [ -n "$TEST_FILES" ]; then
            echo "Test files found, running pytest..."
            
            # Run all tests including smoke tests
            pytest --cov=. --cov-report=xml --cov-report=term-missing \
              --tb=short \
              -v \
              --durations=10
              
            # Run specific smoke tests for marketplace signup flow
            echo "ðŸš¨ Running critical path smoke tests..."
            pytest tests/integration/test_marketplace_signup_smoke.py::test_end_to_end_marketplace_signup \
              -v \
              --tb=short \
              -x
              
          else
            echo "No test files found in project directories, skipping tests"
            echo "This is expected for projects without tests yet."
            # Create a dummy coverage.xml file to satisfy later steps
            mkdir -p .
            echo '<?xml version="1.0" ?><coverage version="7.0.0"><sources></sources><packages></packages></coverage>' > ./coverage.xml
          fi
        env:
          DATABASE_URL: postgresql://factoryadmin:localpass@localhost:5432/factorydb
          DB_HOST: localhost
          DB_USER: factoryadmin
          DB_PASS: localpass
          DB_NAME: factorydb
          DB_PORT: 5432
          # Enable smoke test mode
          SMOKE_TEST_MODE: true
          MOCK_EMAIL_SERVICE: true
          
      - name: Setup Snyk CLI
        uses: snyk/actions/setup@master
        env:
          SNYK_TOKEN: ${{ secrets.SNYK_TOKEN }}
          
      - name: Run Snyk Security Scan
        run: |
          # Run Snyk test on all projects
          echo "Running Snyk security scan..."
          snyk test --all-projects --json > snyk-results.json || true
          
          # Display results summary
          echo "Snyk scan completed. Results:"
          snyk test --all-projects --severity-threshold=high || echo "High/Critical vulnerabilities found"
          
          # Upload results as artifact
          if [ -f snyk-results.json ]; then
            echo "Snyk results file created successfully"
            ls -la snyk-results.json
          else
            echo "No Snyk results file found"
          fi
        env:
          SNYK_TOKEN: ${{ secrets.SNYK_TOKEN }}
        continue-on-error: true
        
      - name: Upload Snyk results
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: snyk-security-report
          path: snyk-results.json
          retention-days: 30
          
      - name: Upload coverage to Codecov
        if: success() && hashFiles('./coverage.xml') != ''
        uses: codecov/codecov-action@v4
        with:
          file: ./coverage.xml
          fail_ci_if_error: false

  test-gpt4o:
    runs-on: ubuntu-latest
    name: Test with GPT-4o
    if: ${{ secrets.OPENAI_API_KEY != '' }}
    
    services:
      postgres:
        image: pgvector/pgvector:pg15
        env:
          POSTGRES_DB: factorydb
          POSTGRES_USER: factoryadmin
          POSTGRES_PASSWORD: localpass
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 5432:5432

    steps:
      - uses: actions/checkout@v4
      
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.12'
          
      - name: Cache Python dependencies
        uses: actions/cache@v4
        with:
          path: ~/.cache/pip
          key: ${{ runner.os }}-pip-${{ hashFiles('**/requirements*.txt') }}
          restore-keys: |
            ${{ runner.os }}-pip-
            
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          # Install common development dependencies
          pip install black ruff pytest pytest-cov
          # Install project dependencies if they exist
          if [ -f requirements.txt ]; then pip install -r requirements.txt; fi
          if [ -f agents/dev/starter-api/requirements.txt ]; then pip install -r agents/dev/starter-api/requirements.txt; fi
          if [ -f orchestrator/requirements.txt ]; then pip install -r orchestrator/requirements.txt; fi
          
      - name: Validate orchestrator dependencies
        run: |
          if [ -f orchestrator/requirements.in ]; then
            echo "Checking orchestrator dependency lock file..."
            cd orchestrator
            pip install pip-tools
            pip-compile requirements.in --resolver=backtracking -o requirements.txt.tmp
            if ! diff -q requirements.txt requirements.txt.tmp > /dev/null; then
              echo "ERROR: requirements.txt is out of sync with requirements.in"
              echo "Please run: cd orchestrator && pip-compile requirements.in --resolver=backtracking -o requirements.txt"
              exit 1
            fi
            rm requirements.txt.tmp
            echo "âœ“ Orchestrator dependencies are in sync"
          fi
          
      - name: Create pgvector extension
        run: |
          PGPASSWORD=localpass psql -h localhost -U factoryadmin -d factorydb -c "CREATE EXTENSION IF NOT EXISTS vector;"
          
      - name: Lint with ruff
        run: |
          # Stop the build if there are Python syntax errors or undefined names
          ruff check --select=E9,F63,F7,F82 --statistics .
          # Exit-zero treats all errors as warnings
          ruff check --exit-zero --statistics .
          
      - name: Format check with black
        run: |
          black --check --diff .
          
      - name: Run tests with GPT-4o
        run: |
          # Check for test files in project directories only (exclude venv and third-party)
          TEST_FILES=$(find . -name "*test*.py" -o -name "test_*.py" 2>/dev/null | grep -v -E "(\.venv|venv|env|y/google-cloud-sdk|orchestrator/\.venv)" | head -1)
          if [ -n "$TEST_FILES" ]; then
            echo "Test files found, running pytest with GPT-4o..."
            pytest --cov=. --cov-report=xml --cov-report=term-missing
          else
            echo "No test files found in project directories, skipping tests"
            echo "This is expected for projects without tests yet."
            # Create a dummy coverage.xml file to satisfy later steps
            mkdir -p .
            echo '<?xml version="1.0" ?><coverage version="7.0.0"><sources></sources><packages></packages></coverage>' > ./coverage.xml
          fi
        env:
          DATABASE_URL: postgresql://factoryadmin:localpass@localhost:5432/factorydb
          DB_HOST: localhost
          DB_USER: factoryadmin
          DB_PASS: localpass
          DB_NAME: factorydb
          DB_PORT: 5432
          MODEL_PROVIDER: gpt4o
          OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
          
      - name: Setup Snyk CLI
        uses: snyk/actions/setup@master
        env:
          SNYK_TOKEN: ${{ secrets.SNYK_TOKEN }}
          
      - name: Run Snyk Security Scan
        run: |
          # Run Snyk test on all projects
          echo "Running Snyk security scan..."
          snyk test --all-projects --json > snyk-results.json || true
          
          # Display results summary
          echo "Snyk scan completed. Results:"
          snyk test --all-projects --severity-threshold=high || echo "High/Critical vulnerabilities found"
          
          # Upload results as artifact
          if [ -f snyk-results.json ]; then
            echo "Snyk results file created successfully"
            ls -la snyk-results.json
          else
            echo "No Snyk results file found"
          fi
        env:
          SNYK_TOKEN: ${{ secrets.SNYK_TOKEN }}
        continue-on-error: true
        
      - name: Upload Snyk results
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: snyk-security-report-gpt4o
          path: snyk-results.json
          retention-days: 30
          
      - name: Upload coverage to Codecov
        if: success() && hashFiles('./coverage.xml') != ''
        uses: codecov/codecov-action@v4
        with:
          file: ./coverage.xml
          fail_ci_if_error: false 