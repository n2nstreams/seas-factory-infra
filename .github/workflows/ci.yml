name: CI

on:
  push:
    branches: [ main ]
  pull_request:
    branches: [ main ]

jobs:
  test:
    runs-on: ubuntu-latest
    name: Test with Gemini (Default)
    
    services:
      postgres:
        image: pgvector/pgvector:pg15
        env:
          POSTGRES_DB: factorydb
          POSTGRES_USER: factoryadmin
          POSTGRES_PASSWORD: localpass
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 5432:5432

    steps:
      - uses: actions/checkout@v4
      
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.12'
          
      - name: Cache Python dependencies
        uses: actions/cache@v4
        with:
          path: ~/.cache/pip
          key: ${{ runner.os }}-pip-${{ hashFiles('**/requirements*.txt') }}
          restore-keys: |
            ${{ runner.os }}-pip-
            
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          # Install unified CI requirements to avoid conflicts
          if [ -f requirements-ci.txt ]; then
            echo "Installing unified CI requirements..."
            pip install -r requirements-ci.txt
          else
            echo "Installing individual requirements files..."
            # Install common development dependencies
            pip install black ruff pytest pytest-cov
            # Install project dependencies if they exist
            if [ -f requirements-base.txt ]; then pip install -r requirements-base.txt; fi
            if [ -f requirements-agents.txt ]; then pip install -r requirements-agents.txt; fi
            if [ -f orchestrator/requirements-orchestrator.txt ]; then pip install -r orchestrator/requirements-orchestrator.txt; fi
            if [ -f api_gateway/requirements.txt ]; then pip install -r api_gateway/requirements.txt; fi
          fi
          
      - name: Validate orchestrator dependencies
        run: |
          if [ -f orchestrator/requirements-orchestrator.txt ]; then
            echo "Checking orchestrator dependency lock file..."
            cd orchestrator
            pip install pip-tools
            if [ -f requirements.in ]; then
              pip-compile requirements.in --resolver=backtracking -o requirements.txt.tmp
              if ! diff -q requirements-orchestrator.txt requirements.txt.tmp > /dev/null; then
                echo "ERROR: requirements-orchestrator.txt is out of sync with requirements.in"
                echo "Please run: cd orchestrator && pip-compile requirements.in --resolver=backtracking -o requirements-orchestrator.txt"
                exit 1
              fi
              rm requirements.txt.tmp
            fi
            echo "‚úì Orchestrator dependencies are in sync"
            cd ..
          fi
          
      - name: Create pgvector extension
        run: |
          PGPASSWORD=localpass psql -h localhost -U factoryadmin -d factorydb -c "CREATE EXTENSION IF NOT EXISTS vector;"
          
      - name: Lint with ruff
        run: |
          # Stop the build if there are Python syntax errors or undefined names
          ruff check --select=E9,F63,F7,F82 --statistics . || {
            echo "‚ùå Critical Python syntax errors found"
            exit 1
          }
          # Exit-zero treats all errors as warnings
          ruff check --exit-zero --statistics .
          
      - name: Format check with black
        run: |
          black --check --diff . || {
            echo "‚ùå Code formatting issues found. Run: black ."
            exit 1
          }
          
      - name: Run tests
        run: |
          # Check for test files in project directories only (exclude venv and third-party)
          TEST_FILES=$(find . -name "*test*.py" -o -name "test_*.py" 2>/dev/null | grep -v -E "(\.venv|venv|env|y/google-cloud-sdk|orchestrator/\.venv)" | head -1)
          if [ -n "$TEST_FILES" ]; then
            echo "Test files found, running pytest..."
            
            # Run all tests including smoke tests
            pytest --cov=. --cov-report=xml --cov-report=term-missing \
              --tb=short \
              -v \
              --durations=10 || {
              echo "‚ùå Tests failed"
              exit 1
            }
              
            # Run specific smoke tests for marketplace signup flow
            echo "üö® Running critical path smoke tests..."
            if [ -f "tests/integration/test_marketplace_signup_smoke.py" ]; then
              pytest tests/integration/test_marketplace_signup_smoke.py::test_end_to_end_marketplace_signup \
                -v \
                --tb=short \
                -x || {
                echo "‚ùå Critical smoke tests failed"
                exit 1
              }
            else
              echo "‚ö†Ô∏è Smoke test file not found, skipping"
            fi
              
          else
            echo "No test files found in project directories, skipping tests"
            echo "This is expected for projects without tests yet."
            # Create a dummy coverage.xml file to satisfy later steps
            mkdir -p .
            echo '<?xml version="1.0" ?><coverage version="7.0.0"><sources></sources><packages></packages></coverage>' > ./coverage.xml
          fi
        env:
          DATABASE_URL: postgresql://factoryadmin:localpass@localhost:5432/factorydb
          DB_HOST: localhost
          DB_USER: factoryadmin
          DB_PASS: localpass
          DB_NAME: factorydb
          DB_PORT: 5432
          # Enable smoke test mode
          SMOKE_TEST_MODE: true
          MOCK_EMAIL_SERVICE: true
          
      - name: Setup Snyk CLI
        uses: snyk/actions/setup@master
        env:
          SNYK_TOKEN: ${{ secrets.SNYK_TOKEN }}
          
      - name: Run Snyk Security Scan
        run: |
          # Run Snyk test on all projects
          echo "Running Snyk security scan..."
          snyk test --all-projects --json > snyk-results.json || true
          
          # Display results summary
          echo "Snyk scan completed. Results:"
          snyk test --all-projects --severity-threshold=high || echo "High/Critical vulnerabilities found"
          
          # Upload results as artifact
          if [ -f snyk-results.json ]; then
            echo "Snyk results file created successfully"
            ls -la snyk-results.json
          else
            echo "No Snyk results file found"
          fi
        env:
          SNYK_TOKEN: ${{ secrets.SNYK_TOKEN }}
        continue-on-error: true
        
      - name: Upload Snyk results
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: snyk-security-report
          path: snyk-results.json
          retention-days: 30
          
      - name: Upload coverage to Codecov
        if: success() && hashFiles('./coverage.xml') != ''
        uses: codecov/codecov-action@v5
        with:
          files: ./coverage.xml
          fail_ci_if_error: false

  test-gpt4o:
    runs-on: ubuntu-latest
    name: Test with GPT-4o

    services:
      postgres:
        image: pgvector/pgvector:pg15
        env:
          POSTGRES_DB: factorydb
          POSTGRES_USER: factoryadmin
          POSTGRES_PASSWORD: localpass
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 5432:5432

    steps:
      - name: Check for OpenAI API Key
        id: check-secret
        run: |
          if [ -z "$OPENAI_API_KEY" ]; then
            echo "Skipping GPT-4o tests - OPENAI_API_KEY not available"
            echo "should_skip=true" >> $GITHUB_OUTPUT
          else
            echo "should_skip=false" >> $GITHUB_OUTPUT
          fi
        env:
          OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}

      - uses: actions/checkout@v4
        if: steps.check-secret.outputs.should_skip == 'false'

      - name: Set up Python
        uses: actions/setup-python@v5
        if: steps.check-secret.outputs.should_skip == 'false'
        with:
          python-version: '3.12'

      - name: Cache Python dependencies
        if: steps.check-secret.outputs.should_skip == 'false'
        uses: actions/cache@v4
        with:
          path: ~/.cache/pip
          key: ${{ runner.os }}-pip-${{ hashFiles('**/requirements*.txt') }}
          restore-keys: |
            ${{ runner.os }}-pip-

      - name: Install dependencies
        if: steps.check-secret.outputs.should_skip == 'false'
        run: |
          python -m pip install --upgrade pip
          # Install unified CI requirements to avoid conflicts
          if [ -f requirements-ci.txt ]; then
            echo "Installing unified CI requirements..."
            pip install -r requirements-ci.txt
          else
            echo "Installing individual requirements files..."
            # Install common development dependencies
            pip install black ruff pytest pytest-cov
            # Install project dependencies if they exist
            if [ -f requirements-base.txt ]; then pip install -r requirements-base.txt; fi
            if [ -f requirements-agents.txt ]; then pip install -r requirements-agents.txt; fi
            if [ -f orchestrator/requirements-orchestrator.txt ]; then pip install -r orchestrator/requirements-orchestrator.txt; fi
            if [ -f api_gateway/requirements.txt ]; then pip install -r api_gateway/requirements.txt; fi
          fi
          
      - name: Validate orchestrator dependencies
        if: steps.check-secret.outputs.should_skip == 'false'
        run: |
          if [ -f orchestrator/requirements-orchestrator.txt ]; then
            echo "Checking orchestrator dependency lock file..."
            cd orchestrator
            pip install pip-tools
            if [ -f requirements.in ]; then
              pip-compile requirements.in --resolver=backtracking -o requirements.txt.tmp
              if ! diff -q requirements-orchestrator.txt requirements.txt.tmp > /dev/null; then
                echo "ERROR: requirements-orchestrator.txt is out of sync with requirements.in"
                echo "Please run: cd orchestrator && pip-compile requirements.in --resolver=backtracking -o requirements-orchestrator.txt"
                exit 1
              fi
              rm requirements.txt.tmp
            fi
            echo "‚úì Orchestrator dependencies are in sync"
            cd ..
          fi

      - name: Create pgvector extension
        if: steps.check-secret.outputs.should_skip == 'false'
        run: |
          PGPASSWORD=localpass psql -h localhost -U factoryadmin -d factorydb -c "CREATE EXTENSION IF NOT EXISTS vector;"

      - name: Lint with ruff
        if: steps.check-secret.outputs.should_skip == 'false'
        run: |
          # Stop the build if there are Python syntax errors or undefined names
          ruff check --select=E9,F63,F7,F82 --statistics . || {
            echo "‚ùå Critical Python syntax errors found"
            exit 1
          }
          # Exit-zero treats all errors as warnings
          ruff check --exit-zero --statistics .

      - name: Format check with black
        if: steps.check-secret.outputs.should_skip == 'false'
        run: |
          black --check --diff . || {
            echo "‚ùå Code formatting issues found. Run: black ."
            exit 1
          }

      - name: Run tests with GPT-4o
        if: steps.check-secret.outputs.should_skip == 'false'
        run: |
          # Check for test files in project directories only (exclude venv and third-party)
          TEST_FILES=$(find . -name "*test*.py" -o -name "test_*.py" 2>/dev/null | grep -v -E "(\.venv|venv|env|y/google-cloud-sdk|orchestrator/\.venv)" | head -1)
          if [ -n "$TEST_FILES" ]; then
            echo "Test files found, running pytest with GPT-4o..."
            pytest --cov=. --cov-report=xml --cov-report=term-missing || {
              echo "‚ùå Tests failed"
              exit 1
            }
          else
            echo "No test files found in project directories, skipping tests"
            echo "This is expected for projects without tests yet."
            # Create a dummy coverage.xml file to satisfy later steps
            mkdir -p .
            echo '<?xml version="1.0" ?><coverage version="7.0.0"><sources></sources><packages></packages></coverage>' > ./coverage.xml
          fi
        env:
          DATABASE_URL: postgresql://factoryadmin:localpass@localhost:5432/factorydb
          DB_HOST: localhost
          DB_USER: factoryadmin
          DB_PASS: localpass
          DB_NAME: factorydb
          DB_PORT: 5432
          MODEL_PROVIDER: gpt4o
          OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}

      - name: Setup Snyk CLI
        if: steps.check-secret.outputs.should_skip == 'false'
        uses: snyk/actions/setup@master
        env:
          SNYK_TOKEN: ${{ secrets.SNYK_TOKEN }}

      - name: Run Snyk Security Scan
        if: steps.check-secret.outputs.should_skip == 'false'
        run: |
          # Run Snyk test on all projects
          echo "Running Snyk security scan..."
          snyk test --all-projects --json > snyk-results.json || true

          # Display results summary
          echo "Snyk scan completed. Results:"
          snyk test --all-projects --severity-threshold=high || echo "High/Critical vulnerabilities found"

          # Upload results as artifact
          if [ -f snyk-results.json ]; then
            echo "Snyk results file created successfully"
            ls -la snyk-results.json
          else
            echo "No Snyk results file found"
          fi
        env:
          SNYK_TOKEN: ${{ secrets.SNYK_TOKEN }}
        continue-on-error: true

      - name: Upload Snyk results
        uses: actions/upload-artifact@v4
        if: steps.check-secret.outputs.should_skip == 'false' && always()
        with:
          name: snyk-security-report-gpt4o
          path: snyk-results.json
          retention-days: 30

      - name: Upload coverage to Codecov
        if: steps.check-secret.outputs.should_skip == 'false' && success() && hashFiles('./coverage.xml') != ''
        uses: codecov/codecov-action@v5
        with:
          files: ./coverage.xml
          fail_ci_if_error: false 